{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Analytics Demo: https://aidemos.microsoft.com/text-analytics\n",
    "\n",
    "Pricing: https://azure.microsoft.com/en-gb/pricing/details/cognitive-services/text-analytics/#pricing\n",
    "\n",
    "Clean Up Azure Resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review1.txt\n",
      "Good Hotel and staff\n",
      "The Royal Hotel, London, UK\n",
      "3/2/2018\n",
      "Clean rooms, good service, great location near Buckingham Palace and Westminster Abbey, and so on. We thoroughly enjoyed our stay. The courtyard is very peaceful and we went to a restaurant which is part of the same group and is Indian ( West coast so plenty of fish) with a Michelin Star. We had the taster menu which was fabulous. The rooms were very well appointed with a kitchen, lounge, bedroom and enormous bathroom. Thoroughly recommended.\n",
      "\n",
      "Review2.txt\n",
      "Tired hotel with poor service\n",
      "The Royal Hotel, London, United Kingdom\n",
      "5/6/2018\n",
      "This is a old hotel (has been around since 1950's) and the room furnishings are average - becoming a bit old now and require changing. The internet didn't work and had to come to one of their office rooms to check in for my flight home. The website says it's close to the British Museum, but it's too far to walk.\n",
      "\n",
      "Review3.txt\n",
      "Tired hotel with poor service\n",
      "The Royal Hotel, London, United Kingdom\n",
      "5/6/2018\n",
      "This is a old hotel (has been around since 1950's) and the room furnishings are average - becoming a bit old now and require changing. The internet didn't work and had to come to one of their office rooms to check in for my flight home. The website says it's close to the British Museum, but it's too far to walk.\n",
      "\n",
      "Review4.txt\n",
      "Very noisy and rooms are tiny\n",
      "The Lombard Hotel, San Francisco, USA\n",
      "9/5/2018\n",
      "Hotel is located on Lombard street which is a very busy SIX lane street directly off the Golden Gate Bridge. Traffic from early morning until late at night especially on weekends. Noise would not be so bad if rooms were better insulated but they are not. Had to put cotton balls in my ears to be able to sleep--was too tired to enjoy the city the next day. Rooms are TINY. I picked the room because it had two queen size beds--but the room barely had space to fit them. With family of four in the room it was tight. With all that said, rooms are clean and they've made an effort to update them. The hotel is in Marina district with lots of good places to eat, within walking distance to Presidio. May be good hotel for young stay-up-late adults on a budget\n",
      "\n",
      "\n",
      "Review5.txt\n",
      "Saturn is the sixth planet from the Sun and the second-largest in the Solar System, after Jupiter. It is a gas giant with an average radius about nine times that of Earth.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Read the reviews in the /data/reviews folder\n",
    "reviews_folder = os.path.join('data', 'text', 'reviews')\n",
    "\n",
    "# Create a collection of reviews with id (file name) and text (contents) properties\n",
    "reviews = []\n",
    "for file_name in os.listdir(reviews_folder):\n",
    "    review_text = open(os.path.join(reviews_folder, file_name),encoding=\"utf8\").read()\n",
    "    review = {\"id\": file_name, \"text\": review_text}\n",
    "    reviews.append(review)\n",
    "\n",
    "for review_num in range(len(reviews)):\n",
    "    # print the review text\n",
    "    print('{}\\n{}\\n'.format(reviews[review_num]['id'], reviews[review_num]['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use cognitive services at End point link using key your key\n"
     ]
    }
   ],
   "source": [
    "cog_key = 'your key'\n",
    "cog_endpoint = 'End point link'\n",
    "\n",
    "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-ai-textanalytics in d:\\anaconda\\anaconda\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.14.0 in d:\\anaconda\\anaconda\\lib\\site-packages (from azure-ai-textanalytics) (1.17.0)\n",
      "Requirement already satisfied: msrest>=0.6.21 in d:\\anaconda\\anaconda\\lib\\site-packages (from azure-ai-textanalytics) (0.6.21)\n",
      "Requirement already satisfied: six>=1.11.0 in d:\\anaconda\\anaconda\\lib\\site-packages (from azure-ai-textanalytics) (1.15.0)\n",
      "Requirement already satisfied: azure-common~=1.1 in d:\\anaconda\\anaconda\\lib\\site-packages (from azure-ai-textanalytics) (1.1.27)\n",
      "Requirement already satisfied: requests>=2.18.4 in d:\\anaconda\\anaconda\\lib\\site-packages (from azure-core<2.0.0,>=1.14.0->azure-ai-textanalytics) (2.24.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in d:\\anaconda\\anaconda\\lib\\site-packages (from msrest>=0.6.21->azure-ai-textanalytics) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\anaconda\\lib\\site-packages (from msrest>=0.6.21->azure-ai-textanalytics) (2020.6.20)\n",
      "Requirement already satisfied: isodate>=0.6.0 in d:\\anaconda\\anaconda\\lib\\site-packages (from msrest>=0.6.21->azure-ai-textanalytics) (0.6.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\anaconda\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.14.0->azure-ai-textanalytics) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\anaconda\\anaconda\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.14.0->azure-ai-textanalytics) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in d:\\anaconda\\anaconda\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.14.0->azure-ai-textanalytics) (3.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\anaconda\\anaconda\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-textanalytics) (3.1.1)\n",
      "Requirement already satisfied: azure-cognitiveservices-language-textanalytics in d:\\anaconda\\anaconda\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: azure-common~=1.1 in d:\\anaconda\\anaconda\\lib\\site-packages (from azure-cognitiveservices-language-textanalytics) (1.1.27)\n",
      "Requirement already satisfied: msrest>=0.5.0 in d:\\anaconda\\anaconda\\lib\\site-packages (from azure-cognitiveservices-language-textanalytics) (0.6.21)\n",
      "Requirement already satisfied: requests~=2.16 in d:\\anaconda\\anaconda\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (2.24.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\anaconda\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (2020.6.20)\n",
      "Requirement already satisfied: isodate>=0.6.0 in d:\\anaconda\\anaconda\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (0.6.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in d:\\anaconda\\anaconda\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (1.3.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\anaconda\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\anaconda\\anaconda\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in d:\\anaconda\\anaconda\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (3.0.4)\n",
      "Requirement already satisfied: six in d:\\anaconda\\anaconda\\lib\\site-packages (from isodate>=0.6.0->msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (1.15.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\anaconda\\anaconda\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-ai-textanalytics\n",
    "!pip install azure-cognitiveservices-language-textanalytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review1.txt\n",
      " - Language: English\n",
      " - Code: en\n",
      " - Score: 1.0\n",
      "\n",
      "Review2.txt\n",
      " - Language: English\n",
      " - Code: en\n",
      " - Score: 1.0\n",
      "\n",
      "Review3.txt\n",
      " - Language: English\n",
      " - Code: en\n",
      " - Score: 1.0\n",
      "\n",
      "Review4.txt\n",
      " - Language: English\n",
      " - Code: en\n",
      " - Score: 1.0\n",
      "\n",
      "Review5.txt\n",
      " - Language: English\n",
      " - Code: en\n",
      " - Score: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.cognitiveservices.language.textanalytics import TextAnalyticsClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "# Get a client for your text analytics cognitive service resource\n",
    "text_analytics_client = TextAnalyticsClient(endpoint=cog_endpoint,\n",
    "                                            credentials=CognitiveServicesCredentials(cog_key))\n",
    "\n",
    "# Analyze the reviews you read from the /data/reviews folder earlier\n",
    "language_analysis = text_analytics_client.detect_language(documents=reviews)\n",
    "\n",
    "# print detected language details for each review\n",
    "for review_num in range(len(reviews)):\n",
    "    # print the review id\n",
    "    print(reviews[review_num]['id'])\n",
    "\n",
    "    # Get the language details for this review\n",
    "    lang = language_analysis.documents[review_num].detected_languages[0]\n",
    "    print(' - Language: {}\\n - Code: {}\\n - Score: {}\\n'.format(lang.name, lang.iso6391_name, lang.score))\n",
    "\n",
    "    # Add the detected language code to the collection of reviews (so we can do further analysis)\n",
    "    reviews[review_num][\"language\"] = lang.iso6391_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "def authenticate_client():\n",
    "    ta_credential = AzureKeyCredential(cog_key)\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "            endpoint=cog_endpoint, \n",
    "            credential=ta_credential)\n",
    "    return text_analytics_client\n",
    "\n",
    "client = authenticate_client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language:  Tamil\n"
     ]
    }
   ],
   "source": [
    "def language_detection_example(client):\n",
    "    try:\n",
    "        documents = [\"சிறப்பு எழுத்துக்குறிகள். இதை மேம்படுத்த உதவவும்! Google உள்ளீட்டு கருவியைப் பெறுக \"]\n",
    "        response = client.detect_language(documents = documents, country_hint = 'us')[0]\n",
    "        print(\"Language: \", response.primary_language.name)\n",
    "\n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))\n",
    "language_detection_example(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Personally Identifiable Information (PII)\n",
    "\n",
    "https://docs.microsoft.com/en-us/azure/cognitive-services/language-service/personally-identifiable-information/concepts/entity-categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redacted Text: ************************************** - ***************************************************, ***********************************************************\n",
      "Entity: Ingram Micro India SSC Private Limited\n",
      "\tCategory: Organization\n",
      "\tConfidence Score: 0.9\n",
      "\tOffset: 0\n",
      "\tLength: 38\n",
      "Entity: Chennai Central Square, I, Guindy Industrial Estate\n",
      "\tCategory: Address\n",
      "\tConfidence Score: 0.92\n",
      "\tOffset: 41\n",
      "\tLength: 51\n",
      "Entity: SIDCO Industrial Estate, Guindy, Chennai, Tamil Nadu 600032\n",
      "\tCategory: Address\n",
      "\tConfidence Score: 0.66\n",
      "\tOffset: 94\n",
      "\tLength: 59\n",
      "Redacted Text: SKCL ************** 1 *****************************\n",
      "Entity: Central Square\n",
      "\tCategory: Address\n",
      "\tConfidence Score: 0.71\n",
      "\tOffset: 5\n",
      "\tLength: 14\n",
      "Entity: https://www.espncricinfo.com/\n",
      "\tCategory: URL\n",
      "\tConfidence Score: 0.8\n",
      "\tOffset: 22\n",
      "\tLength: 29\n",
      "Redacted Text: ************'s origins trace back to the founding of distributor ************* in ********* by ******* and **** team, ********** and **************, who were both ********. The company started in Southern California and in its first year of business achieved approximately $3.5 million in sales.\n",
      "Entity: Ingram Micro\n",
      "\tCategory: Organization\n",
      "\tConfidence Score: 0.87\n",
      "\tOffset: 0\n",
      "\tLength: 12\n",
      "Entity: Micro D, Inc.\n",
      "\tCategory: Organization\n",
      "\tConfidence Score: 0.93\n",
      "\tOffset: 65\n",
      "\tLength: 13\n",
      "Entity: July 1979\n",
      "\tCategory: DateTime\n",
      "\tConfidence Score: 0.8\n",
      "\tOffset: 82\n",
      "\tLength: 9\n",
      "Entity: husband\n",
      "\tCategory: PersonType\n",
      "\tConfidence Score: 0.8\n",
      "\tOffset: 95\n",
      "\tLength: 7\n",
      "Entity: wife\n",
      "\tCategory: PersonType\n",
      "\tConfidence Score: 0.74\n",
      "\tOffset: 107\n",
      "\tLength: 4\n",
      "Entity: Geza Czige\n",
      "\tCategory: Person\n",
      "\tConfidence Score: 0.99\n",
      "\tOffset: 118\n",
      "\tLength: 10\n",
      "Entity: Lorraine Mecca\n",
      "\tCategory: Person\n",
      "\tConfidence Score: 0.99\n",
      "\tOffset: 133\n",
      "\tLength: 14\n",
      "Entity: teachers\n",
      "\tCategory: PersonType\n",
      "\tConfidence Score: 0.97\n",
      "\tOffset: 163\n",
      "\tLength: 8\n"
     ]
    }
   ],
   "source": [
    "#key = \"paste-your-key-here\"\n",
    "#endpoint = \"paste-your-endpoint-here\"\n",
    "\n",
    "\n",
    "# Example method for detecting sensitive information (PII) from text \n",
    "def pii_recognition_example(client):\n",
    "    documents = [\n",
    "        \"Ingram Micro India SSC Private Limited - Chennai Central Square, I, Guindy Industrial Estate, SIDCO Industrial Estate, Guindy, Chennai, Tamil Nadu 600032\",\n",
    "        \"SKCL Central Square 1 https://www.espncricinfo.com/\",\n",
    "        \"Ingram Micro's origins trace back to the founding of distributor Micro D, Inc. in July 1979 by husband and wife team, Geza Czige and Lorraine Mecca, who were both teachers. The company started in Southern California and in its first year of business achieved approximately $3.5 million in sales.\"\n",
    "    ]\n",
    "    response = client.recognize_pii_entities(documents, language=\"en\")\n",
    "    result = [doc for doc in response if not doc.is_error]\n",
    "    for doc in result:\n",
    "        print(\"Redacted Text: {}\".format(doc.redacted_text))\n",
    "        for entity in doc.entities:\n",
    "            print(\"Entity: {}\".format(entity.text))\n",
    "            print(\"\\tCategory: {}\".format(entity.category))\n",
    "            print(\"\\tConfidence Score: {}\".format(entity.confidence_score))\n",
    "            print(\"\\tOffset: {}\".format(entity.offset))\n",
    "            print(\"\\tLength: {}\".format(entity.length))\n",
    "pii_recognition_example(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Phrase extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review1.txt\n",
      "\n",
      "Key Phrases:\n",
      "['Good Hotel', 'good service', 'Clean rooms', 'Royal Hotel', 'great location', 'Buckingham Palace', 'Westminster Abbey', 'fish', 'West coast', 'lounge', 'bedroom', 'enormous bathroom', 'group', 'kitchen', 'London', 'UK', 'taster menu', 'Michelin Star', 'staff', 'courtyard']\n",
      "\t Good Hotel\n",
      "\t good service\n",
      "\t Clean rooms\n",
      "\t Royal Hotel\n",
      "\t great location\n",
      "\t Buckingham Palace\n",
      "\t Westminster Abbey\n",
      "\t fish\n",
      "\t West coast\n",
      "\t lounge\n",
      "\t bedroom\n",
      "\t enormous bathroom\n",
      "\t group\n",
      "\t kitchen\n",
      "\t London\n",
      "\t UK\n",
      "\t taster menu\n",
      "\t Michelin Star\n",
      "\t staff\n",
      "\t courtyard\n",
      "\n",
      "\n",
      "Review2.txt\n",
      "\n",
      "Key Phrases:\n",
      "['old hotel', 'Royal Hotel', 'Tired hotel', 'London', 'United Kingdom', 'room furnishings', 'poor service', 'British Museum', 'website', 'office rooms', 'flight home', 'internet']\n",
      "\t old hotel\n",
      "\t Royal Hotel\n",
      "\t Tired hotel\n",
      "\t London\n",
      "\t United Kingdom\n",
      "\t room furnishings\n",
      "\t poor service\n",
      "\t British Museum\n",
      "\t website\n",
      "\t office rooms\n",
      "\t flight home\n",
      "\t internet\n",
      "\n",
      "\n",
      "Review3.txt\n",
      "\n",
      "Key Phrases:\n",
      "['old hotel', 'Royal Hotel', 'Tired hotel', 'London', 'United Kingdom', 'room furnishings', 'poor service', 'British Museum', 'website', 'office rooms', 'flight home', 'internet']\n",
      "\t old hotel\n",
      "\t Royal Hotel\n",
      "\t Tired hotel\n",
      "\t London\n",
      "\t United Kingdom\n",
      "\t room furnishings\n",
      "\t poor service\n",
      "\t British Museum\n",
      "\t website\n",
      "\t office rooms\n",
      "\t flight home\n",
      "\t internet\n",
      "\n",
      "\n",
      "Review4.txt\n",
      "\n",
      "Key Phrases:\n",
      "['rooms', 'good hotel', 'Lombard Hotel', 'Lombard street', 'late adults', 'good places', 'lane street', 'young stay', 'night', 'early morning', 'Marina district', 'San Francisco', 'USA', 'Golden Gate Bridge', 'walking distance', 'queen size beds', 'ears', 'Traffic', 'cotton balls', 'city', 'Presidio', 'weekends', 'budget', 'day', 'effort', 'Noise', 'space', 'family']\n",
      "\t rooms\n",
      "\t good hotel\n",
      "\t Lombard Hotel\n",
      "\t Lombard street\n",
      "\t late adults\n",
      "\t good places\n",
      "\t lane street\n",
      "\t young stay\n",
      "\t night\n",
      "\t early morning\n",
      "\t Marina district\n",
      "\t San Francisco\n",
      "\t USA\n",
      "\t Golden Gate Bridge\n",
      "\t walking distance\n",
      "\t queen size beds\n",
      "\t ears\n",
      "\t Traffic\n",
      "\t cotton balls\n",
      "\t city\n",
      "\t Presidio\n",
      "\t weekends\n",
      "\t budget\n",
      "\t day\n",
      "\t effort\n",
      "\t Noise\n",
      "\t space\n",
      "\t family\n",
      "\n",
      "\n",
      "Review5.txt\n",
      "\n",
      "Key Phrases:\n",
      "['average radius', 'Solar System', 'times', 'gas giant', 'Jupiter', 'Earth', 'Saturn', 'planet']\n",
      "\t average radius\n",
      "\t Solar System\n",
      "\t times\n",
      "\t gas giant\n",
      "\t Jupiter\n",
      "\t Earth\n",
      "\t Saturn\n",
      "\t planet\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Use the client and reviews you created in the previous code cell to get key phrases\n",
    "key_phrase_analysis = text_analytics_client.key_phrases(documents=reviews)\n",
    "\n",
    "# print key phrases for each review\n",
    "for review_num in range(len(reviews)):\n",
    "    # print the review id\n",
    "    print(reviews[review_num]['id'])\n",
    "\n",
    "    # Get the key phrases in this review\n",
    "    print('\\nKey Phrases:')\n",
    "    key_phrases = key_phrase_analysis.documents[review_num].key_phrases\n",
    "    print(key_phrases)\n",
    "    # Print each key phrase\n",
    "    for key_phrase in key_phrases:\n",
    "        print('\\t', key_phrase)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tKey Phrases:\n",
      "\t\t regular India A player\n",
      "\t\t Saurashtra fast bowler\n",
      "\t\t Thirty-six-year-old Faiz Fazal\n",
      "\t\t A sides.\n",
      "\t\t India opportunities\n",
      "\t\t Jaydev Unadkat\n",
      "\t\t top earner\n",
      "\t\t IPL auctions\n",
      "\t\t consistent wicket-taker\n",
      "\t\t domestic cricket\n",
      "\t\t Abhimanyu Easwaran\n",
      "\t\t Test reserves\n",
      "\t\t Vidarbha captain\n",
      "\t\t Bengal batter\n",
      "\t\t place\n",
      "\t\t 18 internationals\n",
      "\t\t ODI\n",
      "\t\t Zimbabwe\n"
     ]
    }
   ],
   "source": [
    "def key_phrase_extraction_example(client):\n",
    "\n",
    "    try:\n",
    "        documents = [\"Saurashtra fast bowler Jaydev Unadkat, 30, has been a top earner at IPL auctions and a consistent wicket-taker in domestic cricket, but hasn't found a place in India A sides. The last of his 18 internationals came four years ago. Bengal batter Abhimanyu Easwaran, 26, is a regular India A player and was in the Test reserves last year. Thirty-six-year-old Faiz Fazal, batter and Vidarbha captain, has not got any India opportunities since playing an ODI against Zimbabwe in 2016.\"]\n",
    "\n",
    "        response = client.extract_key_phrases(documents = documents)[0]\n",
    "\n",
    "        if not response.is_error:\n",
    "            print(\"\\tKey Phrases:\")\n",
    "            for phrase in response.key_phrases:\n",
    "                print(\"\\t\\t\", phrase)\n",
    "        else:\n",
    "            print(response.id, response.error)\n",
    "\n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))\n",
    "        \n",
    "key_phrase_extraction_example(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/how-tos/text-analytics-how-to-sentiment-analysis?tabs=version-3-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review1.txt : positive (0.9999973773956299)\n",
      "Review2.txt : negative (5.662441253662109e-07)\n",
      "Review3.txt : negative (5.662441253662109e-07)\n",
      "Review4.txt : negative (2.0623207092285156e-05)\n",
      "Review5.txt : positive (0.5)\n"
     ]
    }
   ],
   "source": [
    "# Use the client and reviews you created previously to get sentiment scores\n",
    "sentiment_analysis = text_analytics_client.sentiment(documents=reviews)\n",
    "\n",
    "# Print the results for each review\n",
    "for review_num in range(len(reviews)):\n",
    "\n",
    "    # Get the sentiment score for this review\n",
    "    sentiment_score = sentiment_analysis.documents[review_num].score\n",
    "\n",
    "    # classifiy 'positive' if more than 0.5, \n",
    "    if sentiment_score < 0.5:\n",
    "        sentiment = 'negative'\n",
    "    else:\n",
    "        sentiment = 'positive'\n",
    "\n",
    "    # print file name and sentiment\n",
    "    print('{} : {} ({})'.format(reviews[review_num]['id'], sentiment, sentiment_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Sentiment: negative\n",
      "Overall scores: positive=0.00; neutral=0.00; negative=1.00 \n",
      "\n",
      "Sentence: I am really exhausted with similar work.\n",
      "Sentence sentiment: negative\n",
      "Sentence score:\n",
      "Positive=0.00\n",
      "Neutral=0.00\n",
      "Negative=1.00\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Document Sentiment: negative\n",
      "Overall scores: positive=0.01; neutral=0.16; negative=0.83 \n",
      "\n",
      "Sentence: I can't operate with the key\n",
      "Sentence sentiment: negative\n",
      "Sentence score:\n",
      "Positive=0.01\n",
      "Neutral=0.16\n",
      "Negative=0.83\n",
      "\n",
      "......'negative' target 'key'\n",
      "......Target score:\n",
      "......Positive=0.09\n",
      "......Negative=0.91\n",
      "\n",
      "......'negative' assessment 'operate'\n",
      "......Assessment score:\n",
      "......Positive=0.09\n",
      "......Negative=0.91\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Document Sentiment: positive\n",
      "Overall scores: positive=1.00; neutral=0.00; negative=0.00 \n",
      "\n",
      "Sentence: This is my best work at Test.\n",
      "Sentence sentiment: positive\n",
      "Sentence score:\n",
      "Positive=1.00\n",
      "Neutral=0.00\n",
      "Negative=0.00\n",
      "\n",
      "......'positive' target 'work'\n",
      "......Target score:\n",
      "......Positive=1.00\n",
      "......Negative=0.00\n",
      "\n",
      "......'positive' assessment 'best'\n",
      "......Assessment score:\n",
      "......Positive=1.00\n",
      "......Negative=0.00\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sentiment_analysis_with_opinion_mining_example(client):\n",
    "\n",
    "    documents = [\n",
    "        \"I am really exhausted with similar work.\",\"I can't operate with the key\",\"This is my best work at Test.\"\n",
    "    ]\n",
    "\n",
    "    result = client.analyze_sentiment(documents, show_opinion_mining=True)\n",
    "    doc_result = [doc for doc in result if not doc.is_error]\n",
    "\n",
    "    positive_reviews = [doc for doc in doc_result if doc.sentiment == \"positive\"]\n",
    "    negative_reviews = [doc for doc in doc_result if doc.sentiment == \"negative\"]\n",
    "\n",
    "    positive_mined_opinions = []\n",
    "    mixed_mined_opinions = []\n",
    "    negative_mined_opinions = []\n",
    "\n",
    "    for document in doc_result:\n",
    "        print(\"Document Sentiment: {}\".format(document.sentiment))\n",
    "        print(\"Overall scores: positive={0:.2f}; neutral={1:.2f}; negative={2:.2f} \\n\".format(\n",
    "            document.confidence_scores.positive,\n",
    "            document.confidence_scores.neutral,\n",
    "            document.confidence_scores.negative,\n",
    "        ))\n",
    "        for sentence in document.sentences:\n",
    "            print(\"Sentence: {}\".format(sentence.text))\n",
    "            print(\"Sentence sentiment: {}\".format(sentence.sentiment))\n",
    "            print(\"Sentence score:\\nPositive={0:.2f}\\nNeutral={1:.2f}\\nNegative={2:.2f}\\n\".format(\n",
    "                sentence.confidence_scores.positive,\n",
    "                sentence.confidence_scores.neutral,\n",
    "                sentence.confidence_scores.negative,\n",
    "            ))\n",
    "            for mined_opinion in sentence.mined_opinions:\n",
    "                target = mined_opinion.target\n",
    "                print(\"......'{}' target '{}'\".format(target.sentiment, target.text))\n",
    "                print(\"......Target score:\\n......Positive={0:.2f}\\n......Negative={1:.2f}\\n\".format(\n",
    "                    target.confidence_scores.positive,\n",
    "                    target.confidence_scores.negative,\n",
    "                ))\n",
    "                for assessment in mined_opinion.assessments:\n",
    "                    print(\"......'{}' assessment '{}'\".format(assessment.sentiment, assessment.text))\n",
    "                    print(\"......Assessment score:\\n......Positive={0:.2f}\\n......Negative={1:.2f}\\n\".format(\n",
    "                        assessment.confidence_scores.positive,\n",
    "                        assessment.confidence_scores.negative,\n",
    "                    ))\n",
    "            print(\"\\n\")\n",
    "        print(\"\\n\")\n",
    "          \n",
    "sentiment_analysis_with_opinion_mining_example(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review1.txt\n",
      " - Location: The Royal Hotel (https://en.wikipedia.org/wiki/The_Royal_Hotel)\n",
      " - Location: London (https://en.wikipedia.org/wiki/London)\n",
      " - DateTime: 3/2/2018 \n",
      " - Location: Buckingham Palace (https://en.wikipedia.org/wiki/Buckingham_Palace)\n",
      " - Location: Westminster Abbey (https://en.wikipedia.org/wiki/Westminster_Abbey)\n",
      " - Location: India (https://en.wikipedia.org/wiki/India)\n",
      " - Location: West Coast Main Line (https://en.wikipedia.org/wiki/West_Coast_Main_Line)\n",
      "Review2.txt\n",
      " - Location: The Royal Hotel (https://en.wikipedia.org/wiki/The_Royal_Hotel)\n",
      " - Location: London (https://en.wikipedia.org/wiki/London)\n",
      " - Location: London \n",
      " - Location: United Kingdom \n",
      " - DateTime: 5/6/2018 \n",
      " - DateTime: since 1950's \n",
      " - DateTime: now \n",
      " - Location: British Museum (https://en.wikipedia.org/wiki/British_Museum)\n",
      "Review3.txt\n",
      " - Location: The Royal Hotel (https://en.wikipedia.org/wiki/The_Royal_Hotel)\n",
      " - Location: London (https://en.wikipedia.org/wiki/London)\n",
      " - Location: London \n",
      " - Location: United Kingdom \n",
      " - DateTime: 5/6/2018 \n",
      " - DateTime: since 1950's \n",
      " - DateTime: now \n",
      " - Location: British Museum (https://en.wikipedia.org/wiki/British_Museum)\n",
      "Review4.txt\n",
      " - Location: Lombard, Illinois (https://en.wikipedia.org/wiki/Lombard,_Illinois)\n",
      " - Location: San Francisco (https://en.wikipedia.org/wiki/San_Francisco)\n",
      " - Location: Lombard Street (San Francisco) (https://en.wikipedia.org/wiki/Lombard_Street_(San_Francisco))\n",
      " - Location: Lombard \n",
      " - Location: Golden Gate Bridge (https://en.wikipedia.org/wiki/Golden_Gate_Bridge)\n",
      " - DateTime: from early morning \n",
      " - DateTime: night \n",
      " - DateTime: the next day \n",
      " - Location: Marina \n",
      " - Location: Marina District, San Francisco (https://en.wikipedia.org/wiki/Marina_District,_San_Francisco)\n",
      " - Location: Presidio of San Francisco (https://en.wikipedia.org/wiki/Presidio_of_San_Francisco)\n",
      "Review5.txt\n",
      " - Location: Jupiter \n",
      " - Location: Earth \n"
     ]
    }
   ],
   "source": [
    "# Use the client and reviews you created previously to get named entities\n",
    "entity_analysis = text_analytics_client.entities(documents=reviews)\n",
    "\n",
    "# Print the results for each review\n",
    "for review_num in range(len(reviews)):\n",
    "    print(reviews[review_num]['id'])\n",
    "    # Get the named entitites in this review\n",
    "    entities = entity_analysis.documents[review_num].entities\n",
    "    for entity in entities:\n",
    "        # Only print datetime or location entitites\n",
    "        if entity.type in ['DateTime','Location']:\n",
    "            link = '(' + entity.wikipedia_url + ')' if entity.wikipedia_id is not None else ''\n",
    "            print(' - {}: {} {}'.format(entity.type, entity.name, link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities:\n",
      "\n",
      "\tText: \t Italian \tCategory: \t Skill \tSubCategory: \t None \n",
      "\tConfidence Score: \t 0.62 \tLength: \t 7 \tOffset: \t 7 \n",
      "\n",
      "\tText: \t food \tCategory: \t Product \tSubCategory: \t None \n",
      "\tConfidence Score: \t 0.46 \tLength: \t 4 \tOffset: \t 15 \n",
      "\n",
      "\tText: \t Pizza \tCategory: \t Product \tSubCategory: \t None \n",
      "\tConfidence Score: \t 0.99 \tLength: \t 5 \tOffset: \t 32 \n",
      "\n",
      "\tText: \t last week \tCategory: \t DateTime \tSubCategory: \t DateRange \n",
      "\tConfidence Score: \t 0.8 \tLength: \t 9 \tOffset: \t 45 \n",
      "\n",
      "\tText: \t Chennai \tCategory: \t Location \tSubCategory: \t GPE \n",
      "\tConfidence Score: \t 1.0 \tLength: \t 7 \tOffset: \t 58 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def entity_recognition_example(client):\n",
    "\n",
    "    try:\n",
    "        documents = [\"I love Italian food, especially Pizza. I had last week in Chennai\"]\n",
    "        result = client.recognize_entities(documents = documents)[0]\n",
    "\n",
    "        print(\"Named Entities:\\n\")\n",
    "        for entity in result.entities:\n",
    "            print(\"\\tText: \\t\", entity.text, \"\\tCategory: \\t\", entity.category, \"\\tSubCategory: \\t\", entity.subcategory,\n",
    "                    \"\\n\\tConfidence Score: \\t\", round(entity.confidence_score, 2), \"\\tLength: \\t\", entity.length, \"\\tOffset: \\t\", entity.offset, \"\\n\")\n",
    "\n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))\n",
    "entity_recognition_example(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Understanding (LUIS)\n",
    "\n",
    "A natural language understanding (NLU) AI service that allows users to interact with your applications, bots and IoT devices by using natural language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language Detection Demo: https://aidemos.microsoft.com/luis/demo\n",
    "\n",
    "LUIS: https://azure.microsoft.com/en-in/services/cognitive-services/language-understanding-intelligent-service/#overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translating Text\n",
    "\n",
    "https://docs.microsoft.com/en-us/azure/cognitive-services/translator/language-support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use cognitive services in centralindia using key Your Key\n"
     ]
    }
   ],
   "source": [
    "cog_key = 'Your Key'\n",
    "cog_location = 'centralindia'\n",
    "\n",
    "print('Ready to use cognitive services in {} using key {}'.format(cog_location, cog_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saurashtra fast bowler Jaydev Unadkat, 30, has been a top earner at IPL auctions and a consistent wicket-taker in domestic cricket, but hasn't found a place in India A sides. The last of his 18 internationals came four years ago. Bengal batter Abhimanyu Easwaran, 26, is a regular India A player and was in the Test reserves last year. Thirty-six-year-old Faiz Fazal, batter and Vidarbha captain, has not got any India opportunities since playing an ODI against Zimbabwe in 2016. -> Le joueur de bowling rapide de Saurashtra, Jaydev Unadkat, 30 ans, a été l’un des meilleurs revenus aux enchères IPL et un preneur de guichet constant dans le cricket national, mais n’a pas trouvé de place dans les équipes A de l’Inde. Le dernier de ses 18 internationaux est arrivé il y a quatre ans. Le frappeur du Bengale Abhimanyu Easwaran, 26 ans, est un joueur régulier de l’Inde A et était dans la réserve de test l’année dernière. Faiz Fazal, trente-six ans, frappeur et capitaine de Vidarbha, n’a pas eu d’opportunités en Inde depuis qu’il a joué un ODI contre le Zimbabwe en 2016.\n"
     ]
    }
   ],
   "source": [
    "# Create a function that makes a REST request to the Text Translation service\n",
    "def translate_text(cog_location, cog_key, text, to_lang='fr', from_lang='en'):\n",
    "    import requests, uuid, json\n",
    "\n",
    "    # Create the URL for the Text Translator service REST request\n",
    "    path = 'https://api.cognitive.microsofttranslator.com/translate?api-version=3.0'\n",
    "    params = '&from={}&to={}'.format(from_lang, to_lang)\n",
    "    constructed_url = path + params\n",
    "\n",
    "    # Prepare the request headers with Cognitive Services resource key and region\n",
    "    headers = {\n",
    "        'Ocp-Apim-Subscription-Key': cog_key,\n",
    "        'Ocp-Apim-Subscription-Region':cog_location,\n",
    "        'Content-type': 'application/json',\n",
    "        'X-ClientTraceId': str(uuid.uuid4())\n",
    "    }\n",
    "\n",
    "    # Add the text to be translated to the body\n",
    "    body = [{\n",
    "        'text': text\n",
    "    }]\n",
    "\n",
    "    # Get the translation\n",
    "    request = requests.post(constructed_url, headers=headers, json=body)\n",
    "    response = request.json()\n",
    "    return response[0][\"translations\"][0][\"text\"]\n",
    "\n",
    "\n",
    "# Test the function\n",
    "text_to_translate = \"Saurashtra fast bowler Jaydev Unadkat, 30, has been a top earner at IPL auctions and a consistent wicket-taker in domestic cricket, but hasn't found a place in India A sides. The last of his 18 internationals came four years ago. Bengal batter Abhimanyu Easwaran, 26, is a regular India A player and was in the Test reserves last year. Thirty-six-year-old Faiz Fazal, batter and Vidarbha captain, has not got any India opportunities since playing an ODI against Zimbabwe in 2016.\"\n",
    "\n",
    "translation = translate_text(cog_location, cog_key, text_to_translate, to_lang='fr', from_lang='en')\n",
    "print('{} -> {}'.format(text_to_translate,translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello -> Ciao\n"
     ]
    }
   ],
   "source": [
    "text_to_translate = \"Hello\"\n",
    "\n",
    "translation = translate_text(cog_location, cog_key, text_to_translate, to_lang='it-IT', from_lang='en-GB')\n",
    "print('{} -> {}'.format(text_to_translate,translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello -> 你好\n"
     ]
    }
   ],
   "source": [
    "text_to_translate = \"Hello\"\n",
    "\n",
    "translation = translate_text(cog_location, cog_key, text_to_translate, to_lang='zh-CN', from_lang='en-US')\n",
    "print('{} -> {}'.format(text_to_translate,translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "गनेशन क्रिकेट का शौकीन था । अंग्रेजी कक्षा के बाद जब वह खेल के मैदान के लिए दौड़ता था । खेल का मैदान दूर होने की वजह उसे हमेशा देर हो जाती थी । उसके पुराने मित्रों ने उसे राजी कर लिया कि वह अगले दो दिन अपनी कक्षा में ना जाये ताकि वह महत्वपूर्ण मैच का अभ्यास कर ले । उसके प्रशिक्षक भी उसकी सहायता को सहमत हो गये कि वह कक्षा अध्यापक को बोल देंगे । लेकिन प्रशिक्षक ने उसे धोखा दिया और गनेशन को बिना पूर्व अनुमति के दो दिन अनुपस्थित रहने के लिए दण्ड दिया गया । -> Ganesan was fond of cricket. After english class when he ran to the playground. He was always late because the playground was far away. His old friends persuaded him not to go to his class for the next two days so that he could practice the important match. His instructor also agreed to his help that he would speak to the class teacher. But the instructor cheated on him and Ganation was punished for being absent for two days without prior permission.\n"
     ]
    }
   ],
   "source": [
    "text_to_translate = \"गनेशन क्रिकेट का शौकीन था । अंग्रेजी कक्षा के बाद जब वह खेल के मैदान के लिए दौड़ता था । खेल का मैदान दूर होने की वजह उसे हमेशा देर हो जाती थी । उसके पुराने मित्रों ने उसे राजी कर लिया कि वह अगले दो दिन अपनी कक्षा में ना जाये ताकि वह महत्वपूर्ण मैच का अभ्यास कर ले । उसके प्रशिक्षक भी उसकी सहायता को सहमत हो गये कि वह कक्षा अध्यापक को बोल देंगे । लेकिन प्रशिक्षक ने उसे धोखा दिया और गनेशन को बिना पूर्व अनुमति के दो दिन अनुपस्थित रहने के लिए दण्ड दिया गया ।\"\n",
    "\n",
    "translation = translate_text(cog_location, cog_key, text_to_translate, to_lang='en-US', from_lang='hi')\n",
    "print('{} -> {}'.format(text_to_translate,translation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move Forward:\n",
    "\n",
    "https://gentle-pebble-08cfc3110.azurestaticapps.net/#about\n",
    "\n",
    "https://vivekraja98.medium.com/literature-text-translation-audio-synthesis-using-microsoft-azure-cognitive-services-5e35add0c79e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/quickstarts/client-libraries-rest-api?tabs=version-3-2&pivots=programming-language-python\n",
    "\n",
    "https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/how-tos/text-analytics-how-to-call-api?tabs=synchronous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Power BI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Returns key phrases from the text in a comma-separated list\n",
    "(text) => let\n",
    "    apikey      = \"YOUR_API_KEY_HERE\",\n",
    "    endpoint    = \"https://<your-custom-subdomain>.cognitiveservices.azure.com/text/analytics\" & \"/v3.0/keyPhrases\",\n",
    "    jsontext    = Text.FromBinary(Json.FromValue(Text.Start(Text.Trim(text), 5000))),\n",
    "    jsonbody    = \"{ documents: [ { language: \"\"en\"\", id: \"\"0\"\", text: \" & jsontext & \" } ] }\",\n",
    "    bytesbody   = Text.ToBinary(jsonbody),\n",
    "    headers     = [#\"Ocp-Apim-Subscription-Key\" = apikey],\n",
    "    bytesresp   = Web.Contents(endpoint, [Headers=headers, Content=bytesbody]),\n",
    "    jsonresp    = Json.Document(bytesresp),\n",
    "    keyphrases  = Text.Lower(Text.Combine(jsonresp[documents]{0}[keyPhrases], \", \"))\n",
    "in  keyphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Returns the sentiment label of the text, for example, positive, negative or mixed.\n",
    "(text) => let\n",
    "    apikey = \"YOUR_API_KEY_HERE\",\n",
    "    endpoint = \"<your-custom-subdomain>.cognitiveservices.azure.com\" & \"/text/analytics/v3.1/sentiment\",\n",
    "    jsontext = Text.FromBinary(Json.FromValue(Text.Start(Text.Trim(text), 5000))),\n",
    "    jsonbody = \"{ documents: [ { language: \"\"en\"\", id: \"\"0\"\", text: \" & jsontext & \" } ] }\",\n",
    "    bytesbody = Text.ToBinary(jsonbody),\n",
    "    headers = [#\"Ocp-Apim-Subscription-Key\" = apikey],\n",
    "    bytesresp = Web.Contents(endpoint, [Headers=headers, Content=bytesbody]),\n",
    "    jsonresp = Json.Document(bytesresp),\n",
    "    sentiment   = jsonresp[documents]{0}[sentiment] \n",
    "    in sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Returns the two-letter language code (for example, 'en' for English) of the text\n",
    "(text) => let\n",
    "    apikey      = \"YOUR_API_KEY_HERE\",\n",
    "    endpoint    = \"https://<your-custom-subdomain>.cognitiveservices.azure.com\" & \"/text/analytics/v3.1/languages\",\n",
    "    jsontext    = Text.FromBinary(Json.FromValue(Text.Start(Text.Trim(text), 5000))),\n",
    "    jsonbody    = \"{ documents: [ { id: \"\"0\"\", text: \" & jsontext & \" } ] }\",\n",
    "    bytesbody   = Text.ToBinary(jsonbody),\n",
    "    headers     = [#\"Ocp-Apim-Subscription-Key\" = apikey],\n",
    "    bytesresp   = Web.Contents(endpoint, [Headers=headers, Content=bytesbody]),\n",
    "    jsonresp    = Json.Document(bytesresp),\n",
    "    language    = jsonresp [documents]{0}[detectedLanguage] [iso6391Name] in language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Returns the name (for example, 'English') of the language in which the text is written\n",
    "(text) => let\n",
    "    apikey      = \"YOUR_API_KEY_HERE\",\n",
    "    endpoint    = \"https://<your-custom-subdomain>.cognitiveservices.azure.com\" & \"/text/analytics/v3.1/languages\",\n",
    "    jsontext    = Text.FromBinary(Json.FromValue(Text.Start(Text.Trim(text), 5000))),\n",
    "    jsonbody    = \"{ documents: [ { id: \"\"0\"\", text: \" & jsontext & \" } ] }\",\n",
    "    bytesbody   = Text.ToBinary(jsonbody),\n",
    "    headers     = [#\"Ocp-Apim-Subscription-Key\" = apikey],\n",
    "    bytesresp   = Web.Contents(endpoint, [Headers=headers, Content=bytesbody]),\n",
    "    jsonresp    = Json.Document(bytesresp),\n",
    "    language    jsonresp [documents]{0}[detectedLanguage] [iso6391Name] in language"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
